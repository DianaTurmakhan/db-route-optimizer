{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import folium\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\",\n",
    "    database=\"data\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\"\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "table_names = [\n",
    "    'cars',\n",
    "    'drivers',\n",
    "    'spatial_ref_sys',\n",
    "    'tc_positions_recent',\n",
    "    'traccar_traccardevice' \n",
    "]\n",
    "\n",
    "\n",
    "dataframes = {}\n",
    "for table_name in table_names:\n",
    "    cursor.execute(f\"SELECT * FROM public.{table_name}\")\n",
    "    rows = cursor.fetchall()\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.columns = [desc[0] for desc in cursor.description]\n",
    "    dataframes[table_name] = df\n",
    "\n",
    "for table_name, df in dataframes.items():\n",
    "    print(f\"Table: {table_name}\")\n",
    "    print(df)\n",
    "    print()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\",\n",
    "    database=\"data\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\"\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "table_names = [\n",
    "    'shuttle.bus_stops',\n",
    "    'shuttle.ride_reviews',\n",
    "    'shuttle.rides',\n",
    "    'shuttle.route_bus_stops',\n",
    "    'shuttle.routes',\n",
    "    'shuttle.tour_bus_stops',\n",
    "    'shuttle.tours',\n",
    "]\n",
    "\n",
    "\n",
    "for table_name in table_names:\n",
    "    cursor.execute(f\"SELECT * FROM public.\\\"{table_name}\\\"\")\n",
    "    rows = cursor.fetchall()\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.columns = [desc[0] for desc in cursor.description]\n",
    "    dataframes[table_name] = df\n",
    "\n",
    "for table_name, df in dataframes.items():\n",
    "    print(f\"Table: {table_name}\")\n",
    "    print(df)\n",
    "    print()\n",
    "    \n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tables:\n",
    "    cars = dataframes['cars']\n",
    "    drivers  = dataframes['drivers']\n",
    "    spatial_ref_sys  = dataframes['spatial_ref_sys']\n",
    "    tc_positions_recent  = dataframes['tc_positions_recent']\n",
    "    traccar_traccardevice  = dataframes['traccar_traccardevice']\n",
    "    shuttle_bus_stops  = dataframes['shuttle.bus_stops']\n",
    "    shuttle_ride_reviews = dataframes['shuttle.ride_reviews']\n",
    "    shuttle_rides = dataframes['shuttle.rides']\n",
    "    shuttle_route_bus_stops = dataframes['shuttle.route_bus_stops']\n",
    "    shuttle_routes = dataframes['shuttle.routes']\n",
    "    shuttle_tour_bus_stops = dataframes['shuttle.tour_bus_stops']\n",
    "    shuttle_tours = dataframes['shuttle.tours']\n",
    "    \n",
    "tables = Tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to get the latitude and the longitude of the location names of the bus_stops\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "geolocator = Nominatim(user_agent=\"my_geocoder\")\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY = 2\n",
    "\n",
    "def geocode_with_retries(location_name):\n",
    "    retries = 0\n",
    "    while retries < MAX_RETRIES:\n",
    "        try:\n",
    "            location = geolocator.geocode(location_name)\n",
    "            if location:\n",
    "                return location.latitude, location.longitude\n",
    "            else:\n",
    "                return None, None\n",
    "        except Exception as e:\n",
    "            print(f\"Geocoding error: {e}. Retrying in {RETRY_DELAY} seconds...\")\n",
    "            retries += 1\n",
    "            time.sleep(RETRY_DELAY)\n",
    "    print(\"Geocoding failed after multiple retries.\")\n",
    "    return None, None\n",
    "\n",
    "tables.shuttle_tour_bus_stops[['latitude', 'longitude']] = tables.shuttle_tour_bus_stops['name'].apply(geocode_with_retries).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to get the latitude and the longitude of the location names of the bus_stops and trying different API so everypoints gets its for every row\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "API_KEY = 'AIzaSyD6VhIKcDwSD3cCInBBMVagOKh3-MfyYKk'  \n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY = 2\n",
    "\n",
    "def geocode_with_retries(location_name):\n",
    "    retries = 0\n",
    "    while retries < MAX_RETRIES:\n",
    "        try:\n",
    "            url = f'https://maps.googleapis.com/maps/api/geocode/json?address={location_name}&key={API_KEY}'\n",
    "            response = requests.get(url)\n",
    "            data = response.json()\n",
    "            if data['results']:\n",
    "                location = data['results'][0]['geometry']['location']\n",
    "                return location['lat'], location['lng']\n",
    "            else:\n",
    "                return None, None\n",
    "        except Exception as e:\n",
    "            print(f\"Geocoding error: {e}. Retrying in {RETRY_DELAY} seconds...\")\n",
    "            retries += 1\n",
    "            time.sleep(RETRY_DELAY)\n",
    "    print(\"Geocoding failed after multiple retries.\")\n",
    "    return None, None\n",
    "\n",
    "geocoded_rows = []\n",
    "for index, row in tables.shuttle_tour_bus_stops.iterrows():\n",
    "    name = row['name']\n",
    "    latitude = row['latitude']\n",
    "    longitude = row['longitude']\n",
    "    if np.isnan(latitude) or np.isnan(longitude):\n",
    "        geocoded_latitude, geocoded_longitude = geocode_with_retries(name)\n",
    "        tables.shuttle_tour_bus_stops.at[index, 'latitude'] = geocoded_latitude\n",
    "        tables.shuttle_tour_bus_stops.at[index, 'longitude'] = geocoded_longitude\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "API_KEY = 'c912d3d66966463c93ed88f28d942495'\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY = 2\n",
    "\n",
    "def geocode_with_retries(location_name):\n",
    "    retries = 0\n",
    "    while retries < MAX_RETRIES:\n",
    "        try:\n",
    "            url = f'https://api.opencagedata.com/geocode/v1/json?q={location_name}&key={API_KEY}'\n",
    "            response = requests.get(url)\n",
    "            data = response.json()\n",
    "            if data['results']:\n",
    "                location = data['results'][0]['geometry']\n",
    "                return location['lat'], location['lng']\n",
    "            else:\n",
    "                return None, None\n",
    "        except Exception as e:\n",
    "            print(f\"Geocoding error: {e}. Retrying in {RETRY_DELAY} seconds...\")\n",
    "            retries += 1\n",
    "            time.sleep(RETRY_DELAY)\n",
    "    print(\"Geocoding failed after multiple retries.\")\n",
    "    return None, None\n",
    "\n",
    "geocoded_rows = []\n",
    "for index, row in tables.shuttle_tour_bus_stops.iterrows():\n",
    "    name = row['name']\n",
    "    latitude = row['latitude']\n",
    "    longitude = row['longitude']\n",
    "    if np.isnan(latitude) or np.isnan(longitude):\n",
    "        geocoded_latitude, geocoded_longitude = geocode_with_retries(name)\n",
    "        tables.shuttle_tour_bus_stops.at[index, 'latitude'] = geocoded_latitude\n",
    "        tables.shuttle_tour_bus_stops.at[index, 'longitude'] = geocoded_longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables.tc_positions_recent = tables.tc_positions_recent.drop('id', axis=1)\n",
    "tables.traccar_traccardevice = tables.traccar_traccardevice.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_driver = pd.merge(tables.tc_positions_recent, tables.traccar_traccardevice, left_on='deviceid', right_on='tc_device_id', how='left', suffixes=('_positions_recent', '_driver'))\n",
    "current_driver = pd.merge(current_driver, tables.drivers, left_on='traccar_user_id', right_on='traccar_user_id', how='left')\n",
    "current_driver.rename(columns={'id': 'driver_id'}, inplace=True)\n",
    "current_driver = pd.merge(current_driver, tables.shuttle_tours, left_on='driver_id', right_on='driver_id', how='left')\n",
    "current_driver.rename(columns={'id': 'tour_id'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\",\n",
    "    database=\"data\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\"\n",
    ")\n",
    "\n",
    "\n",
    "cursor = conn.cursor()\n",
    "table_name = 'shuttle.tour_bus_stops'\n",
    "query = f\"SELECT id, ST_X(location) AS longitude, ST_Y(location) AS latitude, ST_Z(location) AS altitude FROM public.\\\"{table_name}\\\" ORDER BY id\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "location_df = pd.DataFrame(rows, columns=['id', 'longitude', 'latitude', 'altitude'])\n",
    "bus_stops = pd.merge(tables.shuttle_tour_bus_stops, location_df, on='id')\n",
    "print(bus_stops)\n",
    "\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stops.drop('altitude', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(bus_stops, current_driver, left_on=['tour_id'], right_on=['tour_id'], suffixes=('_bus_stops', '_current_driver'), how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_driver.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_driver['servertime'] = pd.to_datetime(current_driver['servertime'])\n",
    "merged_df['driver_time'] = current_driver['servertime'].dt.time\n",
    "merged_df['driver_date'] = current_driver['servertime'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 1\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from folium.vector_layers import PolyLine\n",
    "\n",
    "\n",
    "m = folium.Map(location=[51.1694, 71.4491], zoom_start=12)\n",
    "marker_cluster = MarkerCluster()\n",
    "polylines = {}\n",
    "\n",
    "for index, row in merged_df.iterrows():\n",
    "    driver_latitude = row['latitude']\n",
    "    driver_longitude = row['longitude']\n",
    "    stop_latitude = row['latitude_x']\n",
    "    stop_longitude = row['longitude_x']\n",
    "    tour_id = row['tour_id']\n",
    "\n",
    "    folium.Marker([driver_latitude, driver_longitude]).add_to(marker_cluster)\n",
    "    folium.Marker([stop_latitude, stop_longitude]).add_to(marker_cluster)\n",
    "\n",
    "    polyline = folium.PolyLine(\n",
    "        locations=[[driver_latitude, driver_longitude], [stop_latitude, stop_longitude]],\n",
    "        color='blue',\n",
    "        weight=2.5,\n",
    "        opacity=1\n",
    "    )\n",
    "\n",
    "    if tour_id in polylines:\n",
    "        polylines[tour_id].append(polyline)\n",
    "    else:\n",
    "        polylines[tour_id] = [polyline]\n",
    "\n",
    "\n",
    "for tour_id, polyline_list in polylines.items():\n",
    "    tour_group = folium.FeatureGroup(name=f'Tour {tour_id}')\n",
    "    for polyline in polyline_list:\n",
    "        polyline.add_to(tour_group)\n",
    "    \n",
    "    tour_group.add_to(m)\n",
    "\n",
    "marker_cluster.add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m.save('/Users/diana/desktop/routes_map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop(['id', 'location', 'name', 'bus_stop_id', 'longitude_bus_stops', 'latitude_bus_stops',\n",
    "                'devicetime', 'fixtime', 'latitude_current_driver', 'longitude_current_driver', \n",
    "                'altitude', 'speed', 'course', 'accuracy', 'network', 'traccar_user_id',\n",
    "                'tc_device_id', 'city_id', 'route_id', 'status'],\n",
    "               axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_datetime_with_milliseconds(dt_str):\n",
    "    if isinstance(dt_str, str):\n",
    "        dt_str = dt_str.split('.')[0]\n",
    "    return pd.to_datetime(dt_str, format='%H:%M:%S.%f')\n",
    "\n",
    "merged_df['parsed_arrival_time'] = merged_df['arrival_time'].apply(parse_datetime_with_milliseconds)\n",
    "merged_df['parsed_driver_time'] = merged_df['driver_time'].apply(lambda x: str(x).split('.')[0])  # Remove milliseconds from driver_time\n",
    "\n",
    "merged_df['deviation'] = (pd.to_datetime(merged_df['parsed_driver_time'], format='%H:%M:%S') - merged_df['parsed_arrival_time']).dt.total_seconds() / 60\n",
    "merged_df['missed_stop'] = merged_df['deviation'].apply(lambda x: 1 if x < 0 or pd.isnull(x) else 0)\n",
    "\n",
    "statistics = merged_df.groupby(['driver_id', 'tour_id', 'driver_date']).agg({\n",
    "    'deviation': 'sum',\n",
    "    'missed_stop': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(statistics)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task2\n",
    "def parse_datetime_with_milliseconds(dt_str):\n",
    "    if isinstance(dt_str, str):\n",
    "        dt_str = dt_str.split('.')[0] \n",
    "    return pd.to_datetime(dt_str, format='%H:%M:%S') + pd.Timedelta(milliseconds=731) \n",
    "\n",
    "\n",
    "merged_df['arrival_time'] = merged_df['arrival_time'].apply(parse_datetime_with_milliseconds)\n",
    "merged_df['deviation'] = merged_df['driver_time'].apply(lambda x: pd.to_datetime(str(x), format='%H:%M:%S')) - merged_df['arrival_time']\n",
    "merged_df['deviation'] = merged_df['deviation'].dt.total_seconds() / 60\n",
    "merged_df['missed_stop'] = merged_df['deviation'].apply(lambda x: 1 if x < 0 or pd.isnull(x) else 0)\n",
    "\n",
    "\n",
    "statistics = merged_df.groupby(['driver_id', 'tour_id', 'driver_date']).agg({\n",
    "    'deviation': 'sum',\n",
    "    'missed_stop': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3\n",
    "correlation = statistics['missed_stop'].corr(tables.shuttle_ride_reviews['rating'])\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4\n",
    "tables.shuttle_rides.dropna(subset=['dropoff_tbs_id', 'pickup_tbs_id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df = pd.merge(tables.shuttle_rides, bus_stops[['id', 'longitude', 'latitude']],\n",
    "                     left_on='dropoff_tbs_id', right_on='id', suffixes=('_rides', '_bus_stops'))\n",
    "merged_df = merged_df.rename(columns={'longitude': 'dropoff_longitude', 'latitude': 'dropoff_latitude'})\n",
    "merged_df = merged_df.drop(columns=['id_bus_stops'])\n",
    "merged_df = pd.merge(merged_df, bus_stops[['id', 'longitude', 'latitude']],\n",
    "                     left_on='pickup_tbs_id', right_on='id', suffixes=('_rides', '_bus_stops'))\n",
    "merged_df = merged_df.rename(columns={'longitude': 'pickup_longitude', 'latitude': 'pickup_latitude'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "api_key = 'AIzaSyDr-lCxD65YNlD9NqRrY0TiKpIG2cy69ns'  \n",
    "def calculate_optimized_route(start_latitude, start_longitude, end_latitude, end_longitude, api_key):\n",
    "    url = f\"https://maps.googleapis.com/maps/api/directions/json?origin={start_latitude},{start_longitude}&destination={end_latitude},{end_longitude}&key={api_key}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    route_data = json.loads(response.text)\n",
    "    if route_data[\"status\"] == \"OK\":\n",
    "        optimized_route = route_data[\"routes\"][0][\"overview_polyline\"][\"points\"]\n",
    "        return optimized_route\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "for index, row in merged_df.iterrows():\n",
    "    pickup_latitude = row[\"pickup_latitude\"]\n",
    "    pickup_longitude = row[\"pickup_longitude\"]\n",
    "    dropoff_latitude = row[\"dropoff_latitude\"]\n",
    "    dropoff_longitude = row[\"dropoff_longitude\"]\n",
    "\n",
    "\n",
    "    optimized_route = calculate_optimized_route(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude, api_key)\n",
    "    merged_df.at[index, \"optimized_route\"] = optimized_route\n",
    "\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "OSRM_ENDPOINT = 'http://router.project-osrm.org/route/v1/driving'\n",
    "\n",
    "def calculate_optimized_route(start_latitude, start_longitude, end_latitude, end_longitude):\n",
    "    url = f'{OSRM_ENDPOINT}/{start_longitude},{start_latitude};{end_longitude},{end_latitude}?overview=full&geometries=polyline'\n",
    "    response = requests.get(url)\n",
    "    route_data = response.json()\n",
    "    if 'routes' in route_data and len(route_data['routes']) > 0:\n",
    "        geometry = route_data['routes'][0]['geometry']\n",
    "        return geometry\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "for index, row in merged_df.iterrows():\n",
    "    pickup_latitude = row['pickup_latitude']\n",
    "    pickup_longitude = row['pickup_longitude']\n",
    "    dropoff_latitude = row['dropoff_latitude']\n",
    "    dropoff_longitude = row['dropoff_longitude']\n",
    "\n",
    "    optimized_route = calculate_optimized_route(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude)\n",
    "    merged_df.at[index, 'optimized_route'] = optimized_route\n",
    "\n",
    "print(merged_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "536af85bc128d9275378fa547be457028f45ee4b30f5611e404313b606e0311e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
